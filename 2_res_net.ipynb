{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6396487d-a8b0-4039-a237-ebc95dd4c1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0724ec92-669c-4c47-97df-16a27471ebaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(Block, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.identity_mapping = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.identity_mapping = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        identity = self.identity_mapping(x)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = x + identity\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "481aad21-8997-47bc-8976-efa88b767076",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet34(nn.Module):\n",
    "    def __init__(self, num_classes, blocks):\n",
    "        super(ResNet34, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        self.layer1 = self.make_layer(in_channels=64, out_channels=64, num_blocks=blocks[0], stride=1)\n",
    "        self.layer2 = self.make_layer(in_channels=64, out_channels=128, num_blocks=blocks[1], stride=2)\n",
    "        self.layer3 = self.make_layer(in_channels=128, out_channels=256, num_blocks=blocks[2], stride=2)\n",
    "        self.layer4 = self.make_layer(in_channels=256, out_channels=512, num_blocks=blocks[3], stride=2)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def make_layer(self, in_channels, out_channels, num_blocks, stride):\n",
    "        layers = []\n",
    "        layers.append(Block(in_channels, out_channels, stride))  # Downsampling block\n",
    "        for _ in range(1, num_blocks):\n",
    "            layers.append(Block(out_channels, out_channels))  # Identity blocks\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f84d4f91-4758-452e-95d7-b74e7129c0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.cv_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3997453-2bae-493f-aadb-96b455e21e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = cifar_transform()\n",
    "train_loader, test_loader = download_cifar100(transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf674796-2c17-4e04-9e87-044d64eaa204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current device for training: cuda\n",
      "####################\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "n_epochs = 2\n",
    "save_checkpoint = 1\n",
    "num_classes = 100\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Current device for training:\", device)\n",
    "print(\"#\" * 20)\n",
    "\n",
    "model = ResNet34(num_classes=num_classes, blocks=[3, 4, 6, 3])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "891d1602-2e0d-454b-99dc-8127165017ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model on device:  cuda\n",
      "Epoch 1/10: Train Loss: 3.8309 - Val Loss: 3.2087\n",
      "    Train Acc: 10.92% - Val Acc: 12.50%\n",
      "####################\n",
      "Saving model checkpoint to models/res_net/checkpoint_0.0.pth\n",
      "Epoch 2/10: Train Loss: 2.8432 - Val Loss: 2.5862\n",
      "    Train Acc: 28.00% - Val Acc: 31.25%\n",
      "####################\n",
      "Saving model checkpoint to models/res_net/checkpoint_1.0.pth\n",
      "Epoch 3/10: Train Loss: 2.2511 - Val Loss: 2.2587\n",
      "    Train Acc: 40.28% - Val Acc: 50.00%\n",
      "####################\n",
      "Saving model checkpoint to models/res_net/checkpoint_2.0.pth\n",
      "Epoch 4/10: Train Loss: 1.8381 - Val Loss: 2.2753\n",
      "    Train Acc: 49.76% - Val Acc: 31.25%\n",
      "####################\n",
      "Saving model checkpoint to models/res_net/checkpoint_3.0.pth\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscripts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcv_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m----> 3\u001b[0m epoch_loss_history, batch_loss_history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mres_net\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\MyFolder\\projects\\computer-vision\\scripts\\cv_utils.py:63\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, test_loader, optimizer, criterion, device, model_name, n_epochs, save_checkpoint, save_dir)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     62\u001b[0m     images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 63\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[0;32m     65\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_compile.py:24\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dynamo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[43m)\u001b[49m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_dynamo\\decorators.py:46\u001b[0m, in \u001b[0;36mdisable\u001b[1;34m(fn, recursive)\u001b[0m\n\u001b[0;32m     44\u001b[0m         fn \u001b[38;5;241m=\u001b[39m innermost_fn(fn)\n\u001b[0;32m     45\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(fn)\n\u001b[1;32m---> 46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDisableContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DisableContext()\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:437\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(fn)\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 437\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[43minspect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetsourcefile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    439\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\inspect.py:949\u001b[0m, in \u001b[0;36mgetsourcefile\u001b[1;34m(object)\u001b[0m\n\u001b[0;32m    946\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28many\u001b[39m(filename\u001b[38;5;241m.\u001b[39mendswith(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m\n\u001b[0;32m    947\u001b[0m              importlib\u001b[38;5;241m.\u001b[39mmachinery\u001b[38;5;241m.\u001b[39mEXTENSION_SUFFIXES):\n\u001b[0;32m    948\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 949\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexists\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    950\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m filename\n\u001b[0;32m    951\u001b[0m \u001b[38;5;66;03m# only return a non-existent filename if the module has a PEP 302 loader\u001b[39;00m\n",
      "File \u001b[1;32m<frozen genericpath>:19\u001b[0m, in \u001b[0;36mexists\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from scripts.cv_utils import *\n",
    "\n",
    "epoch_loss_history, batch_loss_history = train(model, train_loader, test_loader, optimizer, criterion, device, model_name=\"res_net\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "881406e1-ff71-4a13-8a69-8aecd38559c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BottleNeck(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, bottleneck_channels=None, stride=1, downsample=None):\n",
    "        super(BottleNeck, self).__init__()\n",
    "        \n",
    "        if bottleneck_channels is not None:\n",
    "            mid_channels = bottleneck_channels\n",
    "        else:\n",
    "            mid_channels = out_channels // 4\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels, mid_channels, kernel_size=1, stride=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(mid_channels)\n",
    "        self.conv2 = nn.Conv2d(mid_channels, mid_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(mid_channels)\n",
    "        self.conv3 = nn.Conv2d(mid_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.identity_mapping = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.identity_mapping = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.identity_mapping(x)\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74829a89-4f10-4c94-8fcd-64d0b6faafa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 64, 56, 56])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(64, 3, 224, 224)\n",
    "conv1 = nn.Sequential(\n",
    "    nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    ")\n",
    "\n",
    "x = conv1(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b8e6148-4932-4b89-bdcd-53c1e3da38f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = 64\n",
    "out_channels = 256\n",
    "stride = 1\n",
    "num_blocks = 3\n",
    "\n",
    "layers = []\n",
    "layers.append(BottleNeck(in_channels, out_channels, bottleneck_channels=64, stride=stride))  # Downsampling block\n",
    "for _ in range(1, num_blocks):\n",
    "    layers.append(BottleNeck(out_channels, out_channels, bottleneck_channels=64))  # Identity blocks\n",
    "\n",
    "\n",
    "layer1 = nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1868a905-97eb-4988-b604-5164368b28ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 256, 56, 56])\n"
     ]
    }
   ],
   "source": [
    "x = layer1(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "143e65d8-111e-4a51-bf8c-de6f2edcfa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = 256\n",
    "out_channels = 512\n",
    "stride = 2\n",
    "num_blocks = 4\n",
    "\n",
    "layers = []\n",
    "layers.append(BottleNeck(in_channels, out_channels, stride=stride, bottleneck_channels=128))  # Downsampling block\n",
    "for _ in range(1, num_blocks):\n",
    "    layers.append(BottleNeck(out_channels, out_channels, bottleneck_channels=128))  # Identity blocks\n",
    "\n",
    "layer1 = nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb903023-a7d3-4ac4-beae-a4095c8c8488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 512, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "x = layer1(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "12d99f67-1962-4e71-b0a9-97dfd5fa3593",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50(nn.Module):\n",
    "    def __init__(self, num_classes=100):\n",
    "        super(ResNet50, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        self.layer1 = self.make_layer(64, 256, 64, stride=1, num_blocks=3)\n",
    "        self.layer2 = self.make_layer(256, 512, 128, stride=2, num_blocks=4)\n",
    "        self.layer3 = self.make_layer(512, 1024, 256, stride=2, num_blocks=6)\n",
    "        self.layer4 = self.make_layer(1024, 2048, 512, stride=2, num_blocks=3)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(2048, num_classes)\n",
    "\n",
    "    def make_layer(self, in_channels, out_channels, bottleneck_channels, stride, num_blocks):\n",
    "        layers = []\n",
    "        layers.append(BottleNeck(in_channels, out_channels, stride=stride, bottleneck_channels=bottleneck_channels))  \n",
    "        for _ in range(1, num_blocks):\n",
    "            layers.append(BottleNeck(out_channels, out_channels, bottleneck_channels=bottleneck_channels)) \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.avg_pool(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b13bf0ca-e3f5-4ada-a3e1-64910e56ba5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 100])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(64, 3, 224, 224)\n",
    "model = ResNet50(100)\n",
    "\n",
    "x = model(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb71f576-51a3-4e47-9da0-8511f1fd3cff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
